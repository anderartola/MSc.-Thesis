\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Deep Learning the Lyman-alpha forest}{29}{chapter.81}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap: deep learning}{{3}{29}{Deep Learning the Lyman-alpha forest}{chapter.81}{}}
\newlabel{chap: deep learning@cref}{{[chapter][3][]3}{[1][29][]29}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Introduction and motivation for the use of Deep Learning}{29}{section.82}\protected@file@percent }
\newlabel{sec:motiv_ml}{{3.1}{29}{Introduction and motivation for the use of Deep Learning}{section.82}{}}
\newlabel{sec:motiv_ml@cref}{{[section][1][3]3.1}{[1][29][]29}}
\newlabel{fig:MLP}{{3.1a}{30}{Graph for a simple MLP with a hidden layer (in orange) and an output neuron (in cyan).\relax }{figure.caption.85}{}}
\newlabel{fig:MLP@cref}{{[subfigure][1][3,1]3.1a}{[1][30][]30}}
\newlabel{sub@fig:MLP}{{a}{30}{Graph for a simple MLP with a hidden layer (in orange) and an output neuron (in cyan).\relax }{figure.caption.85}{}}
\newlabel{sub@fig:MLP@cref}{{[subfigure][1][3,1]3.1a}{[1][30][]30}}
\newlabel{fig:MLP_approx}{{3.1b}{30}{Unit impulse (in black) and the output of the MLP shown in cyan approximating the impulse. \relax }{figure.caption.85}{}}
\newlabel{fig:MLP_approx@cref}{{[subfigure][2][3,1]3.1b}{[1][30][]30}}
\newlabel{sub@fig:MLP_approx}{{b}{30}{Unit impulse (in black) and the output of the MLP shown in cyan approximating the impulse. \relax }{figure.caption.85}{}}
\newlabel{sub@fig:MLP_approx@cref}{{[subfigure][2][3,1]3.1b}{[1][30][]30}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces A simple multilayer perceptron (MLP) with a single hidden layer and a $\tanh {}$ activation function can approximate a unit pulse function. From left to right and top to bottom, the three biases are $\{0, 20, 0\}$ and the four weights are $\{20, -20, 1/2, 1/2\}$.\relax }}{30}{figure.caption.85}\protected@file@percent }
\newlabel{fig:ML MLP approx}{{3.1}{30}{A simple multilayer perceptron (MLP) with a single hidden layer and a $\tanh {}$ activation function can approximate a unit pulse function. From left to right and top to bottom, the three biases are $\{0, 20, 0\}$ and the four weights are $\{20, -20, 1/2, 1/2\}$.\relax }{figure.caption.85}{}}
\newlabel{fig:ML MLP approx@cref}{{[figure][1][3]3.1}{[1][30][]30}}
\newlabel{th:aprox}{{1}{30}{Universal approximation theorem}{theorem.84}{}}
\newlabel{th:aprox@cref}{{[theorem][1][]1}{[1][30][]30}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Evolution of the largest supercomputers in the \href  {https://top500.org}{\textsc  {TOP500}} list in recent years (x-axis). The y-axis shows the peak performance in GFLOPS for the first-ranked computer (red), the last-ranked computer (yellow), and the cumulative power for the top 500 computers (blue). Source: \href  {https://en.wikipedia.org/wiki/History_of_supercomputing}{"History of Supercomputing." Wikipedia, Wikimedia Foundation, 25 Jul. 2024. Accessed 24 Sept. 2024.}.\relax }}{31}{figure.caption.86}\protected@file@percent }
\newlabel{fig:ML_HPC}{{3.2}{31}{Evolution of the largest supercomputers in the \href {https://top500.org}{\textsc {TOP500}} list in recent years (x-axis). The y-axis shows the peak performance in GFLOPS for the first-ranked computer (red), the last-ranked computer (yellow), and the cumulative power for the top 500 computers (blue). Source: \href {https://en.wikipedia.org/wiki/History_of_supercomputing}{"History of Supercomputing." Wikipedia, Wikimedia Foundation, 25 Jul. 2024. Accessed 24 Sept. 2024.}.\relax }{figure.caption.86}{}}
\newlabel{fig:ML_HPC@cref}{{[figure][2][3]3.2}{[1][31][]31}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Histogram showing the number of SNe discovered each year as given by the Asiago Supernova Catalogue \blx@tocontentsinit {0}\cite {SN_year}. \relax }}{33}{figure.caption.90}\protected@file@percent }
\newlabel{fig:Supernovas_per_year}{{3.3}{33}{Histogram showing the number of SNe discovered each year as given by the Asiago Supernova Catalogue \cite {SN_year}. \relax }{figure.caption.90}{}}
\newlabel{fig:Supernovas_per_year@cref}{{[figure][3][3]3.3}{[1][33][]33}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Figure extracted from \blx@tocontentsinit {0}\cite {wdm_from_field}. The left panel shows a sample image density field used in the training data by the authors, with varied image resolution. The right panel shows a sample of predicted WDM masses versus the true WDM mass of the simulation for their fiducial neural network, which can accurately recover the WDM model within a 1 KeV accuracy of up to 10 KeV.\relax }}{35}{figure.caption.91}\protected@file@percent }
\newlabel{fig:ML paper wdm field}{{3.4}{35}{Figure extracted from \cite {wdm_from_field}. The left panel shows a sample image density field used in the training data by the authors, with varied image resolution. The right panel shows a sample of predicted WDM masses versus the true WDM mass of the simulation for their fiducial neural network, which can accurately recover the WDM model within a 1 KeV accuracy of up to 10 KeV.\relax }{figure.caption.91}{}}
\newlabel{fig:ML paper wdm field@cref}{{[figure][4][3]3.4}{[1][35][]35}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Figure extracted from \blx@tocontentsinit {0}\cite {lynna} showing the performance of their neural network recovering thermal parameters on a set of unseen skewers. The true parameter values, shown as dashed lines, are recovered by the average of the point predictions, shown as the dark green cross.\relax }}{36}{figure.caption.92}\protected@file@percent }
\newlabel{fig:ML LYNNA}{{3.5}{36}{Figure extracted from \cite {lynna} showing the performance of their neural network recovering thermal parameters on a set of unseen skewers. The true parameter values, shown as dashed lines, are recovered by the average of the point predictions, shown as the dark green cross.\relax }{figure.caption.92}{}}
\newlabel{fig:ML LYNNA@cref}{{[figure][5][3]3.5}{[1][35][]36}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Fundamentals of (Bayesian) Neural Networks}{37}{section.93}\protected@file@percent }
\newlabel{eq:var_noise_model}{{3.3}{37}{Fundamentals of (Bayesian) Neural Networks}{equation.95}{}}
\newlabel{eq:var_noise_model@cref}{{[equation][3][3]3.3}{[1][37][]37}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Dataset generation, data augmentation and overfitting}{38}{subsection.101}\protected@file@percent }
\newlabel{sec: dataset}{{3.2.1}{38}{Dataset generation, data augmentation and overfitting}{subsection.101}{}}
\newlabel{sec: dataset@cref}{{[subsection][1][3,2]3.2.1}{[1][38][]38}}
\newlabel{eq_ch3:global_loss}{{3.5}{39}{Dataset generation, data augmentation and overfitting}{equation.103}{}}
\newlabel{eq_ch3:global_loss@cref}{{[equation][5][3]3.5}{[1][39][]39}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces The left panel shows the data points (with added noise) generated from a function $f$ in black. Three generative polynomial models are fitted to the data: linear regression in orange, and two smoothing splines in green and blue. The right panel shows the fitting error as a function of the polynomial degree, i.e., the flexibility of the model. The grey curve shows the error on the training dataset, which is monotonically decreasing. The red curve shows the error on the validation dataset, which initially decreases but then grows as the model overfits the training data. Figure extracted from \blx@tocontentsinit {0}\cite {James2021}. \relax }}{40}{figure.caption.105}\protected@file@percent }
\newlabel{fig:ML overfit poly}{{3.6}{40}{The left panel shows the data points (with added noise) generated from a function $f$ in black. Three generative polynomial models are fitted to the data: linear regression in orange, and two smoothing splines in green and blue. The right panel shows the fitting error as a function of the polynomial degree, i.e., the flexibility of the model. The grey curve shows the error on the training dataset, which is monotonically decreasing. The red curve shows the error on the validation dataset, which initially decreases but then grows as the model overfits the training data. Figure extracted from \cite {James2021}. \relax }{figure.caption.105}{}}
\newlabel{fig:ML overfit poly@cref}{{[figure][6][3]3.6}{[1][39][]40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Deep learning architecture}{41}{subsection.107}\protected@file@percent }
\newlabel{sec:deep learning archi}{{3.2.2}{41}{Deep learning architecture}{subsection.107}{}}
\newlabel{sec:deep learning archi@cref}{{[subsection][2][3,2]3.2.2}{[1][41][]41}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Max pooling operation with kernel size $(2,2)$.\relax }}{43}{figure.caption.113}\protected@file@percent }
\newlabel{fig:ML max pool}{{3.7}{43}{Max pooling operation with kernel size $(2,2)$.\relax }{figure.caption.113}{}}
\newlabel{fig:ML max pool@cref}{{[figure][7][3]3.7}{[1][43][]43}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Prediction uncertainty and Bayesian models}{43}{subsection.114}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Illustration for a non-stochastic neural network a), a network with stochastic activations b), and a network with stochastic weights in c). Source: \blx@tocontentsinit {0}\cite {BNN_review}.\relax }}{44}{figure.caption.116}\protected@file@percent }
\newlabel{fig:ML BNN ilus}{{3.8}{44}{Illustration for a non-stochastic neural network a), a network with stochastic activations b), and a network with stochastic weights in c). Source: \cite {BNN_review}.\relax }{figure.caption.116}{}}
\newlabel{fig:ML BNN ilus@cref}{{[figure][8][3]3.8}{[1][44][]44}}
\newlabel{eq:Bayes theorem}{{3.12}{44}{Prediction uncertainty and Bayesian models}{equation.115}{}}
\newlabel{eq:Bayes theorem@cref}{{[equation][12][3]3.12}{[1][44][]44}}
\newlabel{eq:posterior precitive}{{3.14}{45}{Prediction uncertainty and Bayesian models}{equation.118}{}}
\newlabel{eq:posterior precitive@cref}{{[equation][14][3]3.14}{[1][45][]45}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Hyperparameter selection}{45}{subsection.120}\protected@file@percent }
\newlabel{sec:optuna}{{3.2.4}{45}{Hyperparameter selection}{subsection.120}{}}
\newlabel{sec:optuna@cref}{{[subsection][4][3,2]3.2.4}{[1][45][]45}}
\newlabel{eq:expected imp}{{3.15}{46}{Hyperparameter selection}{equation.121}{}}
\newlabel{eq:expected imp@cref}{{[equation][15][3]3.15}{[1][46][]46}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Example KDE estimation for the distribution $l$ and $g$ used in the TPE algorithm. The example shows samples for an arbitrary 2D parametric space $(X, Y)$.\relax }}{47}{figure.caption.126}\protected@file@percent }
\newlabel{fig:ML TPE}{{3.9}{47}{Example KDE estimation for the distribution $l$ and $g$ used in the TPE algorithm. The example shows samples for an arbitrary 2D parametric space $(X, Y)$.\relax }{figure.caption.126}{}}
\newlabel{fig:ML TPE@cref}{{[figure][9][3]3.9}{[1][46][]47}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.5}Loss function and training}{47}{subsection.129}\protected@file@percent }
\newlabel{eq:euclidean norm}{{3.19}{48}{Loss function and training}{equation.131}{}}
\newlabel{eq:euclidean norm@cref}{{[equation][19][3]3.19}{[1][48][]48}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Classical deep learning training loop\relax }}{48}{algorithm.132}\protected@file@percent }
\newlabel{alg:training loop}{{1}{48}{Classical deep learning training loop\relax }{algorithm.132}{}}
\newlabel{alg:training loop@cref}{{[algorithm][1][]1}{[1][48][]48}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Adam optimiser\relax }}{50}{algorithm.146}\protected@file@percent }
\newlabel{alg:adam}{{2}{50}{Adam optimiser\relax }{algorithm.146}{}}
\newlabel{alg:adam@cref}{{[algorithm][2][]2}{[1][49][]50}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Workflow implementation: Recovering IGM conditions from the Lyman-alpha forest}{50}{section.160}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Distributed mirrored learning strategy with two workers (GPUs) and a CPU aggregating the gradient and updating the model parameters.\relax }}{51}{figure.caption.159}\protected@file@percent }
\newlabel{fig:ML mirror training}{{3.10}{51}{Distributed mirrored learning strategy with two workers (GPUs) and a CPU aggregating the gradient and updating the model parameters.\relax }{figure.caption.159}{}}
\newlabel{fig:ML mirror training@cref}{{[figure][10][3]3.10}{[1][50][]51}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Fiducial architecture for our Bayesian neural network trained at $z=4.4$ on the Sherwood simulation suite. The fiducial parameters can be found in Table \ref {table: fiducial architecture}.\relax }}{52}{figure.caption.162}\protected@file@percent }
\newlabel{fig:ML nn architecture}{{3.11}{52}{Fiducial architecture for our Bayesian neural network trained at $z=4.4$ on the Sherwood simulation suite. The fiducial parameters can be found in Table \ref {table: fiducial architecture}.\relax }{figure.caption.162}{}}
\newlabel{fig:ML nn architecture@cref}{{[figure][11][3]3.11}{[1][52][]52}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Hyper-parameter grid search for the fiducial model at $z=4.4$. ``$\log _s$'' indicates the parameter is sampled in the log domain. ``Int'' and ``float'' mean they are sampled as integers or floats, respectively.\relax }}{53}{table.caption.164}\protected@file@percent }
\newlabel{table: fiducial architecture}{{3.1}{53}{Hyper-parameter grid search for the fiducial model at $z=4.4$. ``$\log _s$'' indicates the parameter is sampled in the log domain. ``Int'' and ``float'' mean they are sampled as integers or floats, respectively.\relax }{table.caption.164}{}}
\newlabel{table: fiducial architecture@cref}{{[table][1][3]3.1}{[1][53][]53}}
\newlabel{eq:our loss}{{3.22}{53}{Workflow implementation: Recovering IGM conditions from the Lyman-alpha forest}{equation.165}{}}
\newlabel{eq:our loss@cref}{{[equation][22][3]3.22}{[1][53][]53}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Learning curve for our fiducial architecture at $z=4.4$ on the \texttt  {SHERWOOD} dataset. The figure shows the NLL and the MAE on the validation split as a function of the epoch.\relax }}{55}{figure.caption.166}\protected@file@percent }
\newlabel{fig:ML learning curve}{{3.12}{55}{Learning curve for our fiducial architecture at $z=4.4$ on the \texttt {SHERWOOD} dataset. The figure shows the NLL and the MAE on the validation split as a function of the epoch.\relax }{figure.caption.166}{}}
\newlabel{fig:ML learning curve@cref}{{[figure][12][3]3.12}{[1][54][]55}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces An example 20h$^{-1}$cMpc Lyman-$\alpha $ validation skewer for the CDM and WDM3 Sherwood models. The top panel shows the input flux to the network. The bottom panel shows the true $\Delta _\tau $ density fields, the (mean) recovered densities and the $1\sigma $ envelope predicted by the Bayesian network.\relax }}{56}{figure.caption.167}\protected@file@percent }
\newlabel{fig: example_recovered_skewer}{{3.13}{56}{An example 20h$^{-1}$cMpc Lyman-$\alpha $ validation skewer for the CDM and WDM3 Sherwood models. The top panel shows the input flux to the network. The bottom panel shows the true $\Delta _\tau $ density fields, the (mean) recovered densities and the $1\sigma $ envelope predicted by the Bayesian network.\relax }{figure.caption.167}{}}
\newlabel{fig: example_recovered_skewer@cref}{{[figure][13][3]3.13}{[1][54][]56}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Recovered field statistics and uncertainties}{56}{section.168}\protected@file@percent }
\newlabel{sec:recovered statistics}{{3.4}{56}{Recovered field statistics and uncertainties}{section.168}{}}
\newlabel{sec:recovered statistics@cref}{{[section][4][3]3.4}{[1][55][]56}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Noisy regions and masking}{57}{subsection.169}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Uncertainty in the recovered statistics}{57}{subsection.171}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Sampling from reconstructed density fields}{57}{subsubsection*.173}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces Model $\Delta _\tau $ PDFs for the \texttt  {SHERWOOD} runs computed using the recovered density by our neural network. We explicitly highlight the effect of masking the saturated regions that have a flux $\leq 3\frac  {1}{\mathrm  {SNR}}$. \relax }}{58}{figure.caption.170}\protected@file@percent }
\newlabel{fig: PDF masked unmasked}{{3.14}{58}{Model $\Delta _\tau $ PDFs for the \texttt {SHERWOOD} runs computed using the recovered density by our neural network. We explicitly highlight the effect of masking the saturated regions that have a flux $\leq 3\frac {1}{\mathrm {SNR}}$. \relax }{figure.caption.170}{}}
\newlabel{fig: PDF masked unmasked@cref}{{[figure][14][3]3.14}{[1][57][]58}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.15}{\ignorespaces An example \texttt  {SHERWOOD} CDM skewer, together with the reconstructed $\Delta _\tau $ in blue. The red field shows a resampling without including covariance between the pixels, which generates random noise.\relax }}{59}{figure.caption.174}\protected@file@percent }
\newlabel{fig: resampling indep}{{3.15}{59}{An example \texttt {SHERWOOD} CDM skewer, together with the reconstructed $\Delta _\tau $ in blue. The red field shows a resampling without including covariance between the pixels, which generates random noise.\relax }{figure.caption.174}{}}
\newlabel{fig: resampling indep@cref}{{[figure][15][3]3.15}{[1][59][]59}}
\newlabel{eq: residuals}{{3.23}{59}{Sampling from reconstructed density fields}{equation.175}{}}
\newlabel{eq: residuals@cref}{{[equation][23][3]3.23}{[1][59][]59}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.16}{\ignorespaces The $\Delta _\tau $ correlation matrix $\Sigma $ for the prediction \texttt  {SHERWOOD} CDM residuals as defined in Equation \ref {eq: residuals} at $z=4.4$ for the fiducial trained neural network. Each reconstructed density field has been augmented by applying 1000 translations to generate a smooth matrix.\relax }}{60}{figure.caption.176}\protected@file@percent }
\newlabel{fig: corr mat cdm}{{3.16}{60}{The $\Delta _\tau $ correlation matrix $\Sigma $ for the prediction \texttt {SHERWOOD} CDM residuals as defined in Equation \ref {eq: residuals} at $z=4.4$ for the fiducial trained neural network. Each reconstructed density field has been augmented by applying 1000 translations to generate a smooth matrix.\relax }{figure.caption.176}{}}
\newlabel{fig: corr mat cdm@cref}{{[figure][16][3]3.16}{[1][59][]60}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.17}{\ignorespaces A set of 100 draws including the correlation between nearby pixels for a \texttt  {SHERWOOD} CDM skewer. As opposed to Figure \ref {fig: resampling indep}, the samples are continuous and no longer show noisy behaviour.\relax }}{60}{figure.caption.177}\protected@file@percent }
\newlabel{fig: resampling corr}{{3.17}{60}{A set of 100 draws including the correlation between nearby pixels for a \texttt {SHERWOOD} CDM skewer. As opposed to Figure \ref {fig: resampling indep}, the samples are continuous and no longer show noisy behaviour.\relax }{figure.caption.177}{}}
\newlabel{fig: resampling corr@cref}{{[figure][17][3]3.17}{[1][59][]60}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Intrinsic scatter in the recovered PDF}{61}{subsubsection*.179}\protected@file@percent }
\newlabel{eq:PDF of PDF}{{3.27}{61}{Intrinsic scatter in the recovered PDF}{equation.183}{}}
\newlabel{eq:PDF of PDF@cref}{{[equation][27][3]3.27}{[1][61][]61}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.18}{\ignorespaces Uncertainties on the $\Delta _\tau $ PDF estimated using bootstrapping with 1000 samples and using the standard deviation in Equation \ref {eq:PDF of PDF}. We show the results for 6 CDM skewers with 2048 pixels each from the \texttt  {SHERWOOD} CDM run.\relax }}{62}{figure.caption.184}\protected@file@percent }
\newlabel{fig: boot vs exact}{{3.18}{62}{Uncertainties on the $\Delta _\tau $ PDF estimated using bootstrapping with 1000 samples and using the standard deviation in Equation \ref {eq:PDF of PDF}. We show the results for 6 CDM skewers with 2048 pixels each from the \texttt {SHERWOOD} CDM run.\relax }{figure.caption.184}{}}
\newlabel{fig: boot vs exact@cref}{{[figure][18][3]3.18}{[1][61][]62}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.19}{\ignorespaces $\Delta _\tau $ PDF computed over the full simulation box (that is, using all skewers) compared to the PDF computed using the 60 observed skewers in the \texttt  {SHERWOOD} CDM run at $z=4.4$. We have used the $\Delta _\tau $ fields reconstructed by the fiducial neural network and masked the flux-saturated regions. We find that 60 skewers from the same dataset are sufficient to accurately recover the PDF statistic.\relax }}{63}{figure.caption.185}\protected@file@percent }
\newlabel{fig: PDF sample vs full}{{3.19}{63}{$\Delta _\tau $ PDF computed over the full simulation box (that is, using all skewers) compared to the PDF computed using the 60 observed skewers in the \texttt {SHERWOOD} CDM run at $z=4.4$. We have used the $\Delta _\tau $ fields reconstructed by the fiducial neural network and masked the flux-saturated regions. We find that 60 skewers from the same dataset are sufficient to accurately recover the PDF statistic.\relax }{figure.caption.185}{}}
\newlabel{fig: PDF sample vs full@cref}{{[figure][19][3]3.19}{[1][63][]63}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Model interpretability and limitations}{64}{section.186}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Saliency analysis}{64}{subsection.187}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.20}{\ignorespaces Saliency of the CDM and WDM3 Sherwood network at 8h$^{-1}$cMpc Lyman-$\alpha $ flux. The typical saliency ``length'', that is, the typical number of pixels from the pixel centre that are useful to predict its density is $\sim 30$. Since at redshift $z=4.4$ our pixel scale on the \texttt  {SHERWOOD} data is $1.3$ km/s, we obtain that in velocity space a window of $\sim 40$ km/s is needed to recover the density at a pixel.\relax }}{65}{figure.caption.190}\protected@file@percent }
\newlabel{fig: saliency}{{3.20}{65}{Saliency of the CDM and WDM3 Sherwood network at 8h$^{-1}$cMpc Lyman-$\alpha $ flux. The typical saliency ``length'', that is, the typical number of pixels from the pixel centre that are useful to predict its density is $\sim 30$. Since at redshift $z=4.4$ our pixel scale on the \texttt {SHERWOOD} data is $1.3$ km/s, we obtain that in velocity space a window of $\sim 40$ km/s is needed to recover the density at a pixel.\relax }{figure.caption.190}{}}
\newlabel{fig: saliency@cref}{{[figure][20][3]3.20}{[1][65][]65}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Covariate shift}{65}{subsection.191}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.21}{\ignorespaces The \texttt  {NOTRAIN-WDM1} model predicting on a WDM1 skewer, compared to the fiducial model trained on the whole \texttt  {SHERWOOD} dataset. We find a clear covariate shift effect on \texttt  {NOTRAIN-WDM1}, which biases the recovered $\Delta _\tau $ field. \relax }}{66}{figure.caption.192}\protected@file@percent }
\newlabel{fig: skewer notrain wdm1}{{3.21}{66}{The \texttt {NOTRAIN-WDM1} model predicting on a WDM1 skewer, compared to the fiducial model trained on the whole \texttt {SHERWOOD} dataset. We find a clear covariate shift effect on \texttt {NOTRAIN-WDM1}, which biases the recovered $\Delta _\tau $ field. \relax }{figure.caption.192}{}}
\newlabel{fig: skewer notrain wdm1@cref}{{[figure][21][3]3.21}{[1][66][]66}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.22}{\ignorespaces The \texttt  {NOTRAIN-WDM4} model predicting on a WDM4 skewer, compared to the fiducial model trained on the whole \texttt  {SHERWOOD} dataset. We find that the \texttt  {NOTRAIN-WDM4} predictions show no bias, since WDM4 is bracketed within the training data.\relax }}{67}{figure.caption.193}\protected@file@percent }
\newlabel{fig: skewer notrain wdm4}{{3.22}{67}{The \texttt {NOTRAIN-WDM4} model predicting on a WDM4 skewer, compared to the fiducial model trained on the whole \texttt {SHERWOOD} dataset. We find that the \texttt {NOTRAIN-WDM4} predictions show no bias, since WDM4 is bracketed within the training data.\relax }{figure.caption.193}{}}
\newlabel{fig: skewer notrain wdm4@cref}{{[figure][22][3]3.22}{[1][66][]67}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Extreme covariate shift and malicious data}{67}{subsection.194}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.23}{\ignorespaces Two examples of user-defined input fluxed for our fiducial neural network, featuring examples of extreme covariate shift.\relax }}{68}{figure.caption.195}\protected@file@percent }
\newlabel{fig: skewer malicious}{{3.23}{68}{Two examples of user-defined input fluxed for our fiducial neural network, featuring examples of extreme covariate shift.\relax }{figure.caption.195}{}}
\newlabel{fig: skewer malicious@cref}{{[figure][23][3]3.23}{[1][68][]68}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.4}Model pruning}{68}{subsection.196}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.24}{\ignorespaces First layer activation of the convolutional filters for a trained network with architecture [2, 2], [4, 16] for a randomly selected CDM skewer from \texttt  {SHERWOOD}. We find that channel 1 and 2 are highly redundant, and similarly for channel 3 and 4.\relax }}{69}{figure.caption.197}\protected@file@percent }
\newlabel{fig: filter acti}{{3.24}{69}{First layer activation of the convolutional filters for a trained network with architecture [2, 2], [4, 16] for a randomly selected CDM skewer from \texttt {SHERWOOD}. We find that channel 1 and 2 are highly redundant, and similarly for channel 3 and 4.\relax }{figure.caption.197}{}}
\newlabel{fig: filter acti@cref}{{[figure][24][3]3.24}{[1][69][]69}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.25}{\ignorespaces Training curves for the NLL comparing the model [2, 2], [4, 16] and the pruned architecture [2, 2], [2, 16] with half of the convolutional filters in the first layer. Observe how the pruned architecture performs similarly to the fiducial one, with a more stable learning curve and fewer parameters.\relax }}{70}{figure.caption.198}\protected@file@percent }
\newlabel{fig: pruned NLL}{{3.25}{70}{Training curves for the NLL comparing the model [2, 2], [4, 16] and the pruned architecture [2, 2], [2, 16] with half of the convolutional filters in the first layer. Observe how the pruned architecture performs similarly to the fiducial one, with a more stable learning curve and fewer parameters.\relax }{figure.caption.198}{}}
\newlabel{fig: pruned NLL@cref}{{[figure][25][3]3.25}{[1][69][]70}}
\@setckpt{ML}{
\setcounter{page}{71}
\setcounter{equation}{28}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{10}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{5}
\setcounter{subsection}{4}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{25}
\setcounter{table}{1}
\setcounter{StandardModuleDepth}{0}
\setcounter{parentequation}{0}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{theorem}{1}
\setcounter{float@type}{8}
\setcounter{algorithm}{2}
\setcounter{ALG@line}{12}
\setcounter{ALG@rem}{12}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{121}
\setcounter{maxnames}{10}
\setcounter{minnames}{5}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{0}
\setcounter{maxextradate}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{blx@maxsection}{0}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{section@level}{2}
\setcounter{Item}{9}
\setcounter{Hfootnote}{11}
\setcounter{bookmark@seq@number}{0}
\setcounter{HD@unique}{1}
\setcounter{HD@hypercount}{0}
}
