\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Constraining warm dark matter at the density level}{71}{chapter.199}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{sec: inference pipeline}{{4}{71}{Constraining warm dark matter at the density level}{chapter.199}{}}
\newlabel{sec: inference pipeline@cref}{{[chapter][4][]4}{[1][71][]71}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Inference pipeline: from Lyman-alpha skewers to WDM constraints}{71}{section.200}\protected@file@percent }
\newlabel{sec: inference algo}{{4.1}{71}{Inference pipeline: from Lyman-alpha skewers to WDM constraints}{section.200}{}}
\newlabel{sec: inference algo@cref}{{[section][1][4]4.1}{[1][71][]71}}
\newlabel{eq: chi definition}{{4.1}{72}{Inference pipeline: from Lyman-alpha skewers to WDM constraints}{equation.201}{}}
\newlabel{eq: chi definition@cref}{{[equation][1][4]4.1}{[1][72][]72}}
\newlabel{eq:sigma chi square}{{4.2}{72}{Inference pipeline: from Lyman-alpha skewers to WDM constraints}{equation.202}{}}
\newlabel{eq:sigma chi square@cref}{{[equation][2][4]4.2}{[1][72][]72}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Inference testing on simulated Sherwood spectra under realistic observational conditions}{73}{section.203}\protected@file@percent }
\newlabel{sec:inference test sherwood}{{4.2}{73}{Inference testing on simulated Sherwood spectra under realistic observational conditions}{section.203}{}}
\newlabel{sec:inference test sherwood@cref}{{[section][2][4]4.2}{[1][73][]73}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Untrained DM models}{73}{subsection.204}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Inference results on the \texttt  {NOTRAIN} neural netoworks. Each plot corresponds to a different fit combining predictions from each \texttt  {NOTRAIN} model with each of the masks applied to the PDF when fitting. The light and dark blue regions correspond to the 1 and 2 sigma confidence regions. The red line corresponds to the true DM model mass and the black line to the best-fit model that minimises the $\chi ^2$. The blue curve is the $\chi ^2$ metric. Note that we are using all 5000 sightlines on the inference step.\relax }}{74}{figure.caption.205}\protected@file@percent }
\newlabel{fig:inference no train}{{4.1}{74}{Inference results on the \texttt {NOTRAIN} neural netoworks. Each plot corresponds to a different fit combining predictions from each \texttt {NOTRAIN} model with each of the masks applied to the PDF when fitting. The light and dark blue regions correspond to the 1 and 2 sigma confidence regions. The red line corresponds to the true DM model mass and the black line to the best-fit model that minimises the $\chi ^2$. The blue curve is the $\chi ^2$ metric. Note that we are using all 5000 sightlines on the inference step.\relax }{figure.caption.205}{}}
\newlabel{fig:inference no train@cref}{{[figure][1][4]4.1}{[1][73][]74}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Inference predictions on WDM3 for different combinations of SNR and number of targets N. We find that increasing the target number leads to slightly tighter confidence regions while increasing the SNR leads to more accurate constraints. Most crucially, observe how the true model mass is, in both cases, recovered within $2\sigma $. \relax }}{75}{figure.caption.207}\protected@file@percent }
\newlabel{fig: inference snr vs n}{{4.2}{75}{Inference predictions on WDM3 for different combinations of SNR and number of targets N. We find that increasing the target number leads to slightly tighter confidence regions while increasing the SNR leads to more accurate constraints. Most crucially, observe how the true model mass is, in both cases, recovered within $2\sigma $. \relax }{figure.caption.207}{}}
\newlabel{fig: inference snr vs n@cref}{{[figure][2][4]4.2}{[1][75][]75}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Realistic observational conditions}{75}{subsection.206}\protected@file@percent }
\newlabel{sec:hires test}{{4.2.2}{75}{Realistic observational conditions}{subsection.206}{}}
\newlabel{sec:hires test@cref}{{[subsection][2][4,2]4.2.2}{[1][75][]75}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces The figure shows 100 different $\chi ^2$ fits on 450 \texttt  {SHERWOOD} CDM skerwers and the $2\sigma $ constraints distribution as we vary the exact obsserved draw.\relax }}{76}{figure.caption.209}\protected@file@percent }
\newlabel{fig: inference cdm sherwood}{{4.3}{76}{The figure shows 100 different $\chi ^2$ fits on 450 \texttt {SHERWOOD} CDM skerwers and the $2\sigma $ constraints distribution as we vary the exact obsserved draw.\relax }{figure.caption.209}{}}
\newlabel{fig: inference cdm sherwood@cref}{{[figure][3][4]4.3}{[1][76][]76}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces An example observed $\Delta _\tau $ PDF recovered using 450 simulated CDM skewers and its uncertainties in black, plotted against the model CDM PDF, which is the best-fit model in the $\chi ^2$ test. \relax }}{77}{figure.caption.210}\protected@file@percent }
\newlabel{fig: inference cdm PDF}{{4.4}{77}{An example observed $\Delta _\tau $ PDF recovered using 450 simulated CDM skewers and its uncertainties in black, plotted against the model CDM PDF, which is the best-fit model in the $\chi ^2$ test. \relax }{figure.caption.210}{}}
\newlabel{fig: inference cdm PDF@cref}{{[figure][4][4]4.4}{[1][77][]77}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Summary $2\sigma $ relic WDM constraints based on \blx@tocontentsinit {0}\cite {sherwood_wdm} compared to the forecast obtained in this work. Recall that this forecast has been obtained using simulated data from the \texttt  {SHERWOOD} CDM run, as explained in Section \ref {sec:hires test}.\relax }}{78}{figure.caption.211}\protected@file@percent }
\newlabel{fig: wdm constraints summary}{{4.5}{78}{Summary $2\sigma $ relic WDM constraints based on \cite {sherwood_wdm} compared to the forecast obtained in this work. Recall that this forecast has been obtained using simulated data from the \texttt {SHERWOOD} CDM run, as explained in Section \ref {sec:hires test}.\relax }{figure.caption.211}{}}
\newlabel{fig: wdm constraints summary@cref}{{[figure][5][4]4.5}{[1][77][]78}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Inference on alternative hydrodynamical codes}{78}{section.212}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}The Nyx code}{78}{subsection.213}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces A typical Lyman-$\alpha $ skewer obtained from the Nyx runs with $z_\mathrm  {re}=6$ at $z=4.4$.\relax }}{79}{figure.caption.217}\protected@file@percent }
\newlabel{fig: nyx skewer}{{4.6}{79}{A typical Lyman-$\alpha $ skewer obtained from the Nyx runs with $z_\mathrm {re}=6$ at $z=4.4$.\relax }{figure.caption.217}{}}
\newlabel{fig: nyx skewer@cref}{{[figure][6][4]4.6}{[1][79][]79}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Inference test on Nyx Lyman-alpha skewers}{80}{subsection.219}\protected@file@percent }
\newlabel{eq: chi thermal def}{{4.6}{80}{Inference test on Nyx Lyman-alpha skewers}{equation.222}{}}
\newlabel{eq: chi thermal def@cref}{{[equation][6][4]4.6}{[1][80][]80}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces The 2D distribution of pixels in the temperature-density plane comparing the \texttt  {Nyx} CDM run with $z_\mathrm  {re}=6$ to the \texttt  {SHERWOOD THERMAL} CDM runs. The top panel shows the $95\%$ contours in red and black colours. The bottom panel shows the temperature distribution at the mean density value. As can be observed, the \text  {Nyx} does not fit any of the runs in our training dataset.\relax }}{81}{figure.caption.218}\protected@file@percent }
\newlabel{fig: nyx TD}{{4.7}{81}{The 2D distribution of pixels in the temperature-density plane comparing the \texttt {Nyx} CDM run with $z_\mathrm {re}=6$ to the \texttt {SHERWOOD THERMAL} CDM runs. The top panel shows the $95\%$ contours in red and black colours. The bottom panel shows the temperature distribution at the mean density value. As can be observed, the \text {Nyx} does not fit any of the runs in our training dataset.\relax }{figure.caption.218}{}}
\newlabel{fig: nyx TD@cref}{{[figure][7][4]4.7}{[1][80][]81}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Reconstructed $\Delta _\tau $ density field by the fiducial neural network trained on the \texttt  {SHERWOOD THERMAL} data at $z=4.4$ on a Nyx run. The skewer corresponds to the CDM Nyx run with $z_\mathrm  {re}=6$.\relax }}{82}{figure.caption.220}\protected@file@percent }
\newlabel{fig: nyx rec}{{4.8}{82}{Reconstructed $\Delta _\tau $ density field by the fiducial neural network trained on the \texttt {SHERWOOD THERMAL} data at $z=4.4$ on a Nyx run. The skewer corresponds to the CDM Nyx run with $z_\mathrm {re}=6$.\relax }{figure.caption.220}{}}
\newlabel{fig: nyx rec@cref}{{[figure][8][4]4.8}{[1][80][]82}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}WDM constraints from SQUAD DR1 observational data}{82}{section.223}\protected@file@percent }
\newlabel{sec:inference squad}{{4.4}{82}{WDM constraints from SQUAD DR1 observational data}{section.223}{}}
\newlabel{sec:inference squad@cref}{{[section][4][4]4.4}{[1][82][]82}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Violin plot with the $1\sigma $ residues distribution as defined in Equation \ref {eq: residuals}. Values in the range $[-1,1]$ correspond to pixels that have been successfully recovered within a $1\sigma $ accuracy. Observer how the models with earlier reionization ($z_\mathrm  {re}=7$ and $z_\mathrm  {re}=8$), which have lower temperatures, have a higher recovery rate. This is likely because our training data set contains more WDM models close to CDM, and we know that high WDM masses and low temperate have a degenerate effect on the Lyman-$\alpha $ forest. In general, we note that the $\geq 75 \%$ of the pixels are correctly recovered.\relax }}{83}{figure.caption.221}\protected@file@percent }
\newlabel{fig: nyx violin}{{4.9}{83}{Violin plot with the $1\sigma $ residues distribution as defined in Equation \ref {eq: residuals}. Values in the range $[-1,1]$ correspond to pixels that have been successfully recovered within a $1\sigma $ accuracy. Observer how the models with earlier reionization ($z_\mathrm {re}=7$ and $z_\mathrm {re}=8$), which have lower temperatures, have a higher recovery rate. This is likely because our training data set contains more WDM models close to CDM, and we know that high WDM masses and low temperate have a degenerate effect on the Lyman-$\alpha $ forest. In general, we note that the $\geq 75 \%$ of the pixels are correctly recovered.\relax }{figure.caption.221}{}}
\newlabel{fig: nyx violin@cref}{{[figure][9][4]4.9}{[1][80][]83}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces All 6 sightlines from the SQUAD DR1 sample in Table \ref {tab: squad dr1}. As can be seen, the noise levels vary, depending on the exposure time to the target. All sightlines are 20h$^{-1}$cMpc and centered at $z=4.4$. We show the recovered density field by our fiducial architecture trained on \texttt  {SHERWOOD THERMAL} and retrained with the noise specifications of each target.\relax }}{84}{figure.caption.225}\protected@file@percent }
\newlabel{fig: squad pred}{{4.10}{84}{All 6 sightlines from the SQUAD DR1 sample in Table \ref {tab: squad dr1}. As can be seen, the noise levels vary, depending on the exposure time to the target. All sightlines are 20h$^{-1}$cMpc and centered at $z=4.4$. We show the recovered density field by our fiducial architecture trained on \texttt {SHERWOOD THERMAL} and retrained with the noise specifications of each target.\relax }{figure.caption.225}{}}
\newlabel{fig: squad pred@cref}{{[figure][10][4]4.10}{[1][83][]84}}
\newlabel{tab: squad dr1}{{4.1}{85}{}{table.caption.224}{}}
\newlabel{tab: squad dr1@cref}{{[table][1][4]4.1}{[1][83][]85}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}WDM constraints from GHOST observed spectrum}{85}{section.227}\protected@file@percent }
\newlabel{sec:inference ghost}{{4.5}{85}{WDM constraints from GHOST observed spectrum}{section.227}{}}
\newlabel{sec:inference ghost@cref}{{[section][5][4]4.5}{[1][85][]85}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces In the left panel, we show all 3 $\chi ^2$ curves as a function of the WDM mass, together with the $1,2\sigma $ confidence regions. The right panel shows the recovered $\Delta _\tau $ PDF from the SQUAD DR1 sample with the symmetric uncertainty envelop, together with the best-fit model, corresponding to the CDM cold \texttt  {SHERWOOD THERMAL} model. \relax }}{86}{figure.caption.226}\protected@file@percent }
\newlabel{fig: squad chi pdf}{{4.11}{86}{In the left panel, we show all 3 $\chi ^2$ curves as a function of the WDM mass, together with the $1,2\sigma $ confidence regions. The right panel shows the recovered $\Delta _\tau $ PDF from the SQUAD DR1 sample with the symmetric uncertainty envelop, together with the best-fit model, corresponding to the CDM cold \texttt {SHERWOOD THERMAL} model. \relax }{figure.caption.226}{}}
\newlabel{fig: squad chi pdf@cref}{{[figure][11][4]4.11}{[1][85][]86}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces The GHOST spectrum for J0306+1853 \blx@tocontentsinit {0}\cite {Wang_2015}. The red curve shows the reconstructed continuum together with $1\sigma $ uncertainties, obtained with a PCA technique based on the spectrum to the right side of the Lyman-$\alpha $ line. Observe the DLA at $\sim 1150$ \textup  {~\r A}, which we mask when analysing the Lyman-$\alpha $ forest. \relax }}{86}{figure.caption.228}\protected@file@percent }
\newlabel{fig: ghost spectrum}{{4.12}{86}{The GHOST spectrum for J0306+1853 \cite {Wang_2015}. The red curve shows the reconstructed continuum together with $1\sigma $ uncertainties, obtained with a PCA technique based on the spectrum to the right side of the Lyman-$\alpha $ line. Observe the DLA at $\sim 1150$ \textup {~\AA }, which we mask when analysing the Lyman-$\alpha $ forest. \relax }{figure.caption.228}{}}
\newlabel{fig: ghost spectrum@cref}{{[figure][12][4]4.12}{[1][86][]86}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.13}{\ignorespaces All 20h$^{-1}$cMpc portions of the J0306+1853 spectrum together with the recovered density field. We split the original spectrum into 10 such skewers of the same length as the ones of the \texttt  {SHERWOOD THERMAL} dataset, and consider them independent. For each skewer, we show the closest redshift available in the \texttt  {SHERWOOD} suite on which the neural network has been trained to obtain the predictions.\relax }}{87}{figure.caption.229}\protected@file@percent }
\newlabel{fig: ghost rec}{{4.13}{87}{All 20h$^{-1}$cMpc portions of the J0306+1853 spectrum together with the recovered density field. We split the original spectrum into 10 such skewers of the same length as the ones of the \texttt {SHERWOOD THERMAL} dataset, and consider them independent. For each skewer, we show the closest redshift available in the \texttt {SHERWOOD} suite on which the neural network has been trained to obtain the predictions.\relax }{figure.caption.229}{}}
\newlabel{fig: ghost rec@cref}{{[figure][13][4]4.13}{[1][86][]87}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.14}{\ignorespaces The final $\chi ^2$ metric for our GHOST sample, consisting of 10 skewers in the redshifts $[4.5, 4.6, 4.7, 4.8, 4.9]$. The $\chi ^2$ shown is the mean across the $\chi ^2$ for each redshift.\relax }}{88}{figure.caption.230}\protected@file@percent }
\newlabel{fig: ghost chi}{{4.14}{88}{The final $\chi ^2$ metric for our GHOST sample, consisting of 10 skewers in the redshifts $[4.5, 4.6, 4.7, 4.8, 4.9]$. The $\chi ^2$ shown is the mean across the $\chi ^2$ for each redshift.\relax }{figure.caption.230}{}}
\newlabel{fig: ghost chi@cref}{{[figure][14][4]4.14}{[1][88][]88}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.15}{\ignorespaces The GHOST reconstructed $\Delta _\tau $ PDF at $z=4.9$ obtained from two 20h$^{-1}$cMpc skewers compared to the best fit \texttt  {SHERWOOD} cold CDM at $z=4.9$. We find a good agreement between the model and observed PDF, even when only two skewers are used at each redshift.\relax }}{89}{figure.caption.231}\protected@file@percent }
\newlabel{fig: ghost fit}{{4.15}{89}{The GHOST reconstructed $\Delta _\tau $ PDF at $z=4.9$ obtained from two 20h$^{-1}$cMpc skewers compared to the best fit \texttt {SHERWOOD} cold CDM at $z=4.9$. We find a good agreement between the model and observed PDF, even when only two skewers are used at each redshift.\relax }{figure.caption.231}{}}
\newlabel{fig: ghost fit@cref}{{[figure][15][4]4.15}{[1][88][]89}}
\newlabel{tab: summary constraints}{{4.2}{90}{}{table.caption.232}{}}
\newlabel{tab: summary constraints@cref}{{[table][2][4]4.2}{[1][88][]90}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Comparison of the inference pipeline against Information Maximising Neural Networks}{90}{section.233}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Information Maximising Neural Networks}{90}{subsection.234}\protected@file@percent }
\newlabel{eq:Fisher information}{{4.8}{91}{Information Maximising Neural Networks}{equation.236}{}}
\newlabel{eq:Fisher information@cref}{{[equation][8][4]4.8}{[1][91][]91}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}IMNN training and non-linear summaries}{91}{subsection.237}\protected@file@percent }
\newlabel{eq:IMNN loss}{{4.9}{92}{IMNN training and non-linear summaries}{equation.238}{}}
\newlabel{eq:IMNN loss@cref}{{[equation][9][4]4.9}{[1][92][]92}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.3}Summarising a Gaussian signal}{92}{subsection.240}\protected@file@percent }
\newlabel{sec:IMNN normal}{{4.6.3}{92}{Summarising a Gaussian signal}{subsection.240}{}}
\newlabel{sec:IMNN normal@cref}{{[subsection][3][4,6]4.6.3}{[1][92][]92}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.16}{\ignorespaces $|F|$ and $||C-I||+||C^{-1}-I||$ as a function of the epoch for the training and validation sets during the training of the IMNN on a normal field. The goal is to find summaries to optimally extract information about the mean and variance of the field.\relax }}{93}{figure.caption.243}\protected@file@percent }
\newlabel{fig:IMNN training normal test}{{4.16}{93}{$|F|$ and $||C-I||+||C^{-1}-I||$ as a function of the epoch for the training and validation sets during the training of the IMNN on a normal field. The goal is to find summaries to optimally extract information about the mean and variance of the field.\relax }{figure.caption.243}{}}
\newlabel{fig:IMNN training normal test@cref}{{[figure][16][4]4.16}{[1][93][]93}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.17}{\ignorespaces The IMNN summary plotted against the exact sufficient statistic for the standard deviation using multiple samples with $\sigma \in (0,12)$.\relax }}{94}{figure.caption.244}\protected@file@percent }
\newlabel{fig:IMNN normal std}{{4.17}{94}{The IMNN summary plotted against the exact sufficient statistic for the standard deviation using multiple samples with $\sigma \in (0,12)$.\relax }{figure.caption.244}{}}
\newlabel{fig:IMNN normal std@cref}{{[figure][17][4]4.17}{[1][94][]94}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Approximate Bayesian Computation Rejection Algorithm\relax }}{95}{algorithm.245}\protected@file@percent }
\newlabel{alg:ABC}{{3}{95}{Approximate Bayesian Computation Rejection Algorithm\relax }{algorithm.245}{}}
\newlabel{alg:ABC@cref}{{[algorithm][3][]3}{[1][94][]95}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.4}IMNN inference results on WDM masses}{95}{subsection.259}\protected@file@percent }
\newlabel{sec:IMNN}{{4.6.4}{95}{IMNN inference results on WDM masses}{subsection.259}{}}
\newlabel{sec:IMNN@cref}{{[subsection][4][4,6]4.6.4}{[1][95][]95}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.18}{\ignorespaces Posterior samples and KDE for the ABC rejection algorithm applied to the normal toy model, where we infer the mean and variance of a Gaussian field with flat priors and the summaries output of an IMNN. The dashed vertical lines show the true parameter values.\relax }}{96}{figure.caption.258}\protected@file@percent }
\newlabel{fig:IMNN normal posterior}{{4.18}{96}{Posterior samples and KDE for the ABC rejection algorithm applied to the normal toy model, where we infer the mean and variance of a Gaussian field with flat priors and the summaries output of an IMNN. The dashed vertical lines show the true parameter values.\relax }{figure.caption.258}{}}
\newlabel{fig:IMNN normal posterior@cref}{{[figure][18][4]4.18}{[1][95][]96}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.19}{\ignorespaces $|F|$ and $||C-I||+||C^{-1}-I||$ as a function of the epoch for the training and validation sets during the training of the IMNN on the \texttt  {SHERWOOD} dataset Lyman-$\alpha $ skewers.\relax }}{97}{figure.caption.261}\protected@file@percent }
\newlabel{fig:IMNN wdm training}{{4.19}{97}{$|F|$ and $||C-I||+||C^{-1}-I||$ as a function of the epoch for the training and validation sets during the training of the IMNN on the \texttt {SHERWOOD} dataset Lyman-$\alpha $ skewers.\relax }{figure.caption.261}{}}
\newlabel{fig:IMNN wdm training@cref}{{[figure][19][4]4.19}{[1][95][]97}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.20}{\ignorespaces \relax }}{98}{figure.caption.262}\protected@file@percent }
\newlabel{fig:IMNN WDM posterior}{{4.20}{98}{\relax }{figure.caption.262}{}}
\newlabel{fig:IMNN WDM posterior@cref}{{[figure][20][4]4.20}{[1][97][]98}}
\@setckpt{inference}{
\setcounter{page}{99}
\setcounter{equation}{12}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{2}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{6}
\setcounter{subsection}{4}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{20}
\setcounter{table}{2}
\setcounter{StandardModuleDepth}{0}
\setcounter{parentequation}{0}
\setcounter{caption@flags}{6}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{2}
\setcounter{subtable}{0}
\setcounter{theorem}{1}
\setcounter{float@type}{8}
\setcounter{algorithm}{3}
\setcounter{ALG@line}{12}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{152}
\setcounter{maxnames}{10}
\setcounter{minnames}{5}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{0}
\setcounter{maxextradate}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{blx@maxsection}{0}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{section@level}{2}
\setcounter{Item}{9}
\setcounter{Hfootnote}{13}
\setcounter{bookmark@seq@number}{0}
\setcounter{HD@unique}{1}
\setcounter{HD@hypercount}{0}
}
